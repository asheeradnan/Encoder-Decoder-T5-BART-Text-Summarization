{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\n\nprint(\"Python version:\", sys.version)\nprint(\"Working directory:\", os.getcwd())\n\n!pip install -q transformers==4.44.2 datasets==3.0.2 evaluate==0.4.2 rouge_score==0.1.2\n!pip install -q peft==0.11.1 accelerate==1.0.1\n!pip install -q gradio==4.44.0 sentencepiece protobuf\n\n\ntry:\n    import bitsandbytes\n    print(\"Warning:bitsandbytes found,uninstalling\")\n    !pip uninstall -y bitsandbytes\n    print(\"bitsandbytes removed\")\nexcept ImportError:\n    print(\"bitsandbytes not installed(correct)\")\n\nimport nltk\nnltk.download('punkt', quiet=True)\nnltk.download('punkt_tab', quiet=True)\n\nprint(\"\\nAll packages installed successfully!\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cell2\nimport json\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nfrom datasets import Dataset, DatasetDict\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    DataCollatorForSeq2Seq,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n    set_seed\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    TaskType,\n    PeftModel,\n    PeftConfig\n)\nimport evaluate\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T15:48:46.679127Z","iopub.execute_input":"2025-11-12T15:48:46.680080Z","iopub.status.idle":"2025-11-12T15:48:46.686440Z","shell.execute_reply.started":"2025-11-12T15:48:46.680052Z","shell.execute_reply":"2025-11-12T15:48:46.685668Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.6.0+cu124\nCUDA available: True\nCUDA device: Tesla T4\nCUDA memory: 15.83 GB\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#Cll3Configuration for Better Model\nCONFIG = {\n    \"model_name\": \"facebook/bart-base\",\n    \"run_name\": \"bart_lora_cnndm_improved\",\n    \n    \"data_path\": \"/kaggle/input/newspaper-text-summarization-cnn-dailymail\",\n    \"article_column\": \"article\",\n    \"summary_column\": \"highlights\",\n    \n    \"max_source_length\": 1024,\n    \"max_target_length\": 128,\n    \"num_train_samples\": 50000, \n    \"num_val_samples\": 2000,     \n    \"num_test_samples\": 2000,   \n  \n    \"lora_r\": 32,            \n    \"lora_alpha\": 64,        \n    \"lora_target_modules\": [\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\"], \n    \"lora_dropout\": 0.1,\n    \n    \"learning_rate\": 5e-5,     \n    \"num_epochs\": 4,           \n    \"train_batch_size\": 4,\n    \"eval_batch_size\": 8,\n    \"gradient_accumulation_steps\": 4,\n    \"warmup_ratio\": 0.05,       \n    \"weight_decay\": 0.01,\n    \"lr_scheduler_type\": \"cosine\",\n    \"label_smoothing_factor\": 0.1,\n    \n    \"generation_max_length\": 128,\n    \"generation_num_beams\": 4,\n    \"generation_length_penalty\": 1.8, \n    \"generation_no_repeat_ngram_size\": 3,\n    \n    \"fp16\": True,\n    \"seed\": 42,\n    \"logging_steps\": 100,\n    \"eval_steps\": 1000,         \n    \"save_steps\": 2000,\n    \"save_total_limit\": 3,      \n    \"output_dir\": \"/kaggle/working/checkpoints\",\n    \"results_dir\": \"/kaggle/working/results\",\n}\n\nif \"t5\" in CONFIG[\"model_name\"].lower():\n    CONFIG[\"lora_target_modules\"] = [\"q\", \"v\", \"k\", \"o\"]\n    CONFIG[\"max_source_length\"] = 512\n\nprint(f\"\\nData:\")\nprint(f\"  Training samples: {CONFIG['num_train_samples']:,} (5√ó increase)\")\nprint(f\"  Validation: {CONFIG['num_val_samples']:,}\")\nprint(f\"  Test: {CONFIG['num_test_samples']:,}\")\n\nprint(f\"\\nLoRA:\")\nprint(f\"  Rank: {CONFIG['lora_r']} (2√ó increase)\")\nprint(f\"  Alpha: {CONFIG['lora_alpha']}\")\nprint(f\"  Target modules: {len(CONFIG['lora_target_modules'])} modules\")\n\nprint(f\"\\nTraining:\")\nprint(f\"  Epochs: {CONFIG['num_epochs']}\")\nprint(f\"  Learning rate: {CONFIG['learning_rate']}\")\nprint(f\"  Effective batch: {CONFIG['train_batch_size'] * CONFIG['gradient_accumulation_steps']}\")\n\nestimated_time = (CONFIG['num_train_samples'] / (CONFIG['train_batch_size'] * CONFIG['gradient_accumulation_steps'])) * CONFIG['num_epochs'] * 0.8 / 60\nprint(f\"\\nEstimated training time: ~{estimated_time:.0f} minutes ({estimated_time/60:.1f} hours)\")\n\n\nimport os\nos.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\nos.makedirs(CONFIG[\"results_dir\"], exist_ok=True)\n\nfrom transformers import set_seed\nset_seed(CONFIG[\"seed\"])\nprint(f\"\\nRandom seed set to {CONFIG['seed']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:39:34.669175Z","iopub.status.idle":"2025-11-13T05:39:34.669457Z","shell.execute_reply.started":"2025-11-13T05:39:34.669343Z","shell.execute_reply":"2025-11-13T05:39:34.669353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CELL4Load Dataset \ntrain_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\")\nval_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\")\n\nprint(f\"Dataset loaded:\")\nprint(f\"  Train: {len(train_df):,} samples\")\nprint(f\"  Validation: {len(val_df):,} samples\")\nprint(f\"  Test: {len(test_df):,} samples\")\n\nprint(f\"\\nColumns: {train_df.columns.tolist()}\")\nprint(f\"Using: article ‚Üí highlights\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAMPLE ARTICLE & SUMMARY\")\nprint(\"=\"*80)\nsample = train_df.iloc[0]\nprint(f\"\\nARTICLE ({len(sample['article'])} chars):\")\nprint(sample['article'][:500] + \"...\")\nprint(f\"\\nSUMMARY ({len(sample['highlights'])} chars):\")\nprint(sample['highlights'])\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T15:49:54.928092Z","iopub.execute_input":"2025-11-12T15:49:54.928393Z","iopub.status.idle":"2025-11-12T15:50:10.149968Z","shell.execute_reply.started":"2025-11-12T15:49:54.928370Z","shell.execute_reply":"2025-11-12T15:50:10.149254Z"}},"outputs":[{"name":"stdout","text":"üì• Loading CNN/DailyMail dataset from Kaggle...\n‚úÖ Dataset loaded:\n  Train: 287,113 samples\n  Validation: 13,368 samples\n  Test: 11,490 samples\n\nüìã Columns: ['id', 'article', 'highlights']\n‚úÖ Using: article ‚Üí highlights\n\n================================================================================\nüì∞ SAMPLE ARTICLE & SUMMARY\n================================================================================\n\nüìÑ ARTICLE (1211 chars):\nBy . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in N...\n\n‚ú® SUMMARY (220 chars):\nBishop John Folda, of North Dakota, is taking time off after being diagnosed .\nHe contracted the infection through contaminated food in Italy .\nChurch members in Fargo, Grand Forks and Jamestown could have been exposed .\n================================================================================\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#CELL5Data Preprocessing\ndef clean_text(text):\n    \"\"\"Basic text cleaning\"\"\"\n    if pd.isna(text):\n        return \"\"\n    text = str(text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndef prepare_dataset(df, num_samples=None):\n    \"\"\"Prepare dataset for training\"\"\"\n    df = df.dropna(subset=['article', 'highlights'])\n    df = df[df['article'].str.len() > 50]#drop nulls and very short text\n    df = df[df['highlights'].str.len() > 10]\n    \n    if num_samples and num_samples < len(df):\n        df = df.sample(n=num_samples, random_state=CONFIG['seed']).reset_index(drop=True)\n    \n    df['article'] = df['article'].apply(clean_text)\n    df['highlights'] = df['highlights'].apply(clean_text)\n    \n    return df[['article', 'highlights']]\n\nprint(\"preprocessing datasets\")\n\ntrain_clean = prepare_dataset(train_df, CONFIG['num_train_samples'])\nval_clean = prepare_dataset(val_df, CONFIG['num_val_samples'])\ntest_clean = prepare_dataset(test_df, CONFIG['num_test_samples'])\n\nprint(f\"\\nDataset sizes:\")\nprint(f\"  Train: {len(train_clean):,}\")\nprint(f\"  Validation: {len(val_clean):,}\")\nprint(f\"  Test: {len(test_clean):,}\")\n\nfrom datasets import Dataset, DatasetDict\n\ntrain_dataset = Dataset.from_pandas(train_clean)\nval_dataset = Dataset.from_pandas(val_clean)\ntest_dataset = Dataset.from_pandas(test_clean)\n\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})\n\nprint(\"\\nconverted to HuggingFace Dataset format\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T15:51:12.797634Z","iopub.execute_input":"2025-11-12T15:51:12.798169Z","iopub.status.idle":"2025-11-12T15:51:16.365694Z","shell.execute_reply.started":"2025-11-12T15:51:12.798146Z","shell.execute_reply":"2025-11-12T15:51:16.365044Z"}},"outputs":[{"name":"stdout","text":"üîÑ Preprocessing datasets...\n\n‚úÖ Dataset sizes:\n  Train: 10,000\n  Validation: 1,000\n  Test: 1,000\n\n‚úÖ Converted to HuggingFace Dataset format\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#CELL6\nprint(f\"Loading tokenizer: {CONFIG['model_name']}\")\ntokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'], use_fast=True)\n\ndef preprocess_function(examples):\n    \"\"\"Tokenize articles and summaries\"\"\"\n    # For T5, add task prefix\n    if \"t5\" in CONFIG['model_name'].lower():\n        inputs = [f\"summarize: {doc}\" for doc in examples['article']]\n    else:\n        inputs = examples['article']\n    \n    targets = examples['highlights']\n    \n    model_inputs = tokenizer(\n        inputs,\n        max_length=CONFIG['max_source_length'],\n        padding='max_length',\n        truncation=True,\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets,\n            max_length=CONFIG['max_target_length'],\n            padding='max_length',\n            truncation=True,\n        )\n    \n    labels_ids = labels['input_ids']\n    labels_ids = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in label_ids]\n        for label_ids in labels_ids\n    ]\n    \n    model_inputs['labels'] = labels_ids\n    return model_inputs\n\nprint(\"tokenizing datasets\")\ntokenized_dataset = dataset.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=['article', 'highlights'],\n    desc=\"Tokenizing\",\n)\n\nprint(\"tokenization complete\")\nprint(f\"Sample: input_ids length = {len(tokenized_dataset['train'][0]['input_ids'])}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-12T19:57:30.419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CELL7\nprint(f\"\\nloading base model: {CONFIG['model_name']}\")\n\nimport sys\nif 'bitsandbytes' in sys.modules:\n    print(\"Warning:bitsandbytes is loaded.Removing from cache\")\n    del sys.modules['bitsandbytes']\n\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(CONFIG['model_name'])\nprint(f\"Base model loaded: {sum(p.numel() for p in base_model.parameters()):,} parameters\")\n\nfrom peft import LoraConfig, get_peft_model, TaskType\nimport os\n\nos.environ['BITSANDBYTES_NOWELCOME'] = '1'\n\nlora_config = LoraConfig(\n    r=CONFIG['lora_r'],\n    lora_alpha=CONFIG['lora_alpha'],\n    target_modules=CONFIG['lora_target_modules'],\n    lora_dropout=CONFIG['lora_dropout'],\n    bias=\"none\",\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    inference_mode=False,\n)\n\nprint(\"\\nApplying LoRA adapters...\")\n\nimport peft.tuners.lora.model as lora_model\n\noriginal_create = lora_model.LoraModel._create_new_module\n\ndef patched_create(lora_config, adapter_name, target, **kwargs):\n    from peft.tuners.lora.layer import LoraLayer, dispatch_default\n    \n    new_module = None\n    \n    # Only use default dispatch (skip bnb)\n    new_module = dispatch_default(\n        target,\n        adapter_name,\n        lora_config=lora_config,\n        **kwargs,\n    )\n    \n    return new_module\n\n#apply patch\nlora_model.LoraModel._create_new_module = staticmethod(patched_create)\n\n#apply LoRA\nmodel = get_peft_model(base_model, lora_config)\n\nprint(\"LoRA applied successfully!\")\nprint(\"\\nmodel Statistics:\")\nmodel.print_trainable_parameters()\n\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nall_params = sum(p.numel() for p in model.parameters())\n\nprint(f\"\\nparameter breakdown:\")\nprint(f\"Total parameters:      {all_params:,}\")\nprint(f\"Trainable parameters:  {trainable_params:,}\")\nprint(f\"Trainable %:           {100 * trainable_params / all_params:.2f}%\")\nprint(f\"Memory savings:        ~{100 - (100 * trainable_params / all_params):.0f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:39:34.584838Z","iopub.execute_input":"2025-11-13T05:39:34.585184Z","iopub.status.idle":"2025-11-13T05:39:34.668683Z","shell.execute_reply.started":"2025-11-13T05:39:34.585159Z","shell.execute_reply":"2025-11-13T05:39:34.667471Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/838821809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#CELL7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nloading base model: {CONFIG['model_name']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'bitsandbytes'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CONFIG' is not defined"],"ename":"NameError","evalue":"name 'CONFIG' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"#CELL8:training Setup \nimport evaluate\nfrom evaluate import load\n\ntry:\n    rouge = evaluate.load(\"rouge\")\nexcept AttributeError:\n    print(\"fixing evaluate library compatibility\")\n    from rouge_score import rouge_scorer\n    \n    class RougeMetric:\n        def __init__(self):\n            self.scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        \n        def compute(self, predictions, references, **kwargs):\n            scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n            for pred, ref in zip(predictions, references):\n                score = self.scorer.score(ref, pred)\n                scores['rouge1'].append(score['rouge1'].fmeasure)\n                scores['rouge2'].append(score['rouge2'].fmeasure)\n                scores['rougeL'].append(score['rougeL'].fmeasure)\n            \n            return {\n                'rouge1': sum(scores['rouge1']) / len(scores['rouge1']),\n                'rouge2': sum(scores['rouge2']) / len(scores['rouge2']),\n                'rougeL': sum(scores['rougeL']) / len(scores['rougeL']),\n                'rougeLsum': sum(scores['rougeL']) / len(scores['rougeL']),\n            }\n    \n    rouge = RougeMetric()\n    print(\"using rouge_score fallback\")\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\ndef compute_metrics(eval_pred):\n    \"\"\"Compute ROUGE scores during evaluation (FIXED for overflow)\"\"\"\n    preds, labels = eval_pred\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    vocab_size = tokenizer.vocab_size\n    preds = np.clip(preds, 0, vocab_size - 1)\n    \n    try:\n        decoded_preds = []\n        for pred in preds:\n            # Filter out invalid token IDs\n            valid_pred = [int(t) for t in pred if 0 <= t < vocab_size]\n            decoded_preds.append(tokenizer.decode(valid_pred, skip_special_tokens=True))\n    except Exception as e:\n        print(f\"warning in decoding predictions: {e}\")\n        return {\n            'rouge1': 0.0,\n            'rouge2': 0.0,\n            'rougeL': 0.0,\n            'rougeLsum': 0.0,\n        }\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    \n    labels = np.clip(labels, 0, vocab_size - 1)\n    \n    try:\n        decoded_labels = []\n        for label in labels:\n            valid_label = [int(t) for t in label if 0 <= t < vocab_size]\n            decoded_labels.append(tokenizer.decode(valid_label, skip_special_tokens=True))\n    except Exception as e:\n        print(f\"warning in decoding labels: {e}\")\n        return {\n            'rouge1': 0.0,\n            'rouge2': 0.0,\n            'rougeL': 0.0,\n            'rougeLsum': 0.0,\n        }\n    decoded_preds = [p.strip() if p.strip() else \".\" for p in decoded_preds]\n    decoded_labels = [l.strip() if l.strip() else \".\" for l in decoded_labels]\n    \n    try:\n        result = rouge.compute(\n            predictions=decoded_preds,\n            references=decoded_labels,\n            use_stemmer=True\n        )\n        \n        return {\n            'rouge1': round(result['rouge1'] * 100, 2),\n            'rouge2': round(result['rouge2'] * 100, 2),\n            'rougeL': round(result['rougeL'] * 100, 2),\n            'rougeLsum': round(result.get('rougeLsum', result['rougeL']) * 100, 2),\n        }\n    except Exception as e:\n        print(f\"warning in ROUGE computation: {e}\")\n        return {\n            'rouge1': 0.0,\n            'rouge2': 0.0,\n            'rougeL': 0.0,\n            'rougeLsum': 0.0,\n        }\n\noutput_dir = f\"{CONFIG['output_dir']}/{CONFIG['run_name']}\"\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=output_dir,\n    overwrite_output_dir=True,\n    evaluation_strategy=\"steps\",\n    eval_steps=CONFIG['eval_steps'],\n    logging_steps=CONFIG['logging_steps'],\n    save_steps=CONFIG['save_steps'],\n    save_total_limit=CONFIG['save_total_limit'],\n    learning_rate=CONFIG['learning_rate'],\n    per_device_train_batch_size=CONFIG['train_batch_size'],\n    per_device_eval_batch_size=CONFIG['eval_batch_size'],\n    gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],\n    num_train_epochs=CONFIG['num_epochs'],\n    weight_decay=CONFIG['weight_decay'],\n    warmup_ratio=CONFIG['warmup_ratio'],\n    lr_scheduler_type=CONFIG['lr_scheduler_type'],\n    label_smoothing_factor=CONFIG['label_smoothing_factor'],\n    predict_with_generate=True,\n    generation_max_length=CONFIG['generation_max_length'],\n    generation_num_beams=CONFIG['generation_num_beams'],\n    fp16=CONFIG['fp16'],\n    logging_dir=f\"{output_dir}/logs\",\n    report_to=['tensorboard'],\n    seed=CONFIG['seed'],\n    load_best_model_at_end=True,\n    metric_for_best_model='rougeL',\n    greater_is_better=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset['train'],\n    eval_dataset=tokenized_dataset['validation'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\neffective_batch = CONFIG['train_batch_size'] * CONFIG['gradient_accumulation_steps']\ntotal_steps = len(tokenized_dataset['train']) // effective_batch * CONFIG['num_epochs']\n\nprint(\"training setup complete!\")\nprint(f\"\\ntraining Configuration:\")\nprint(f\"  Training samples:      {len(tokenized_dataset['train']):,}\")\nprint(f\"  Validation samples:    {len(tokenized_dataset['validation']):,}\")\nprint(f\"  Batch size per device: {CONFIG['train_batch_size']}\")\nprint(f\"  Gradient accumulation: {CONFIG['gradient_accumulation_steps']}\")\nprint(f\"  Effective batch size:  {effective_batch}\")\nprint(f\"  Total epochs:          {CONFIG['num_epochs']}\")\nprint(f\"  Total steps:           {total_steps:,}\")\nprint(f\"  Eval every:            {CONFIG['eval_steps']} steps\")\nprint(f\"  Learning rate:         {CONFIG['learning_rate']}\")\nprint(f\"  LR scheduler:          {CONFIG['lr_scheduler_type']}\")\nprint(f\"\\nestimated training time: ~{total_steps * 0.7 / 60:.0f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:39:59.428564Z","iopub.execute_input":"2025-11-13T05:39:59.429546Z","iopub.status.idle":"2025-11-13T05:39:59.454160Z","shell.execute_reply.started":"2025-11-13T05:39:59.429513Z","shell.execute_reply":"2025-11-13T05:39:59.452824Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3792617021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#CELL8:training Setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'"],"ename":"ModuleNotFoundError","evalue":"No module named 'evaluate'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# CELL9Train\nimport pandas as pd\nfrom datetime import datetime\n\nprint(\"=\"*80)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*80)\nprint(f\"Started at: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\nprint(f\"Model: {CONFIG['model_name']}\")\nprint(f\"LoRA Rank: {CONFIG['lora_r']}\")\nprint(f\"Training samples: {len(tokenized_dataset['train']):,}\")\nprint(f\"Estimated time: ~22 minutes\")\nprint(\"=\"*80 + \"\\n\")\n\ncheckpoints = []\nif os.path.exists(output_dir):\n    checkpoints = [d for d in os.listdir(output_dir) if d.startswith('checkpoint-')]\n\nif checkpoints:\n    latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('-')[1]))\n    checkpoint_path = os.path.join(output_dir, latest_checkpoint)\n    print(f\"Found existing checkpoint: {checkpoint_path}\")\n    print(f\"Resuming training from checkpoint\\n\")\n    \n    try:\n        train_result = trainer.train(resume_from_checkpoint=checkpoint_path)\n    except Exception as e:\n        print(f\"Error resuming from checkpoint: {e}\")\n        print(\"Starting fresh training\\n\")\n        train_result = trainer.train()\nelse:\n    print(\"Starting fresh training\\n\")\n    train_result = trainer.train()\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"tRAINING cOMPLETE\")\nprint(\"=\"*80)\nprint(f\"Finished at: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n\nprint(\"\\nFinal Training Metrics:\")\nfor key, value in train_result.metrics.items():\n    if isinstance(value, float):\n        print(f\"  {key:.<35} {value:.4f}\")\n    else:\n        print(f\"  {key:.<35} {value}\")\n\n# Save model\nprint(f\"\\nüíæ Saving model to: {output_dir}\")\ntrainer.save_model(output_dir)\ntokenizer.save_pretrained(output_dir)\n\nprint(\"Saving LoRA adapter weights\")\ntry:\n    model.save_pretrained(output_dir)\n    print(\"LoRA adapters saved\")\nexcept Exception as e:\n    print(f\"LoRA save warning: {e}\")\n\nwith open(f\"{CONFIG['results_dir']}/training_metrics.json\", 'w') as f:\n    json.dump(train_result.metrics, f, indent=2)\n\ntraining_info = {\n    'model': CONFIG['model_name'],\n    'lora_config': {\n        'rank': CONFIG['lora_r'],\n        'alpha': CONFIG['lora_alpha'],\n        'target_modules': CONFIG['lora_target_modules'],\n        'dropout': CONFIG['lora_dropout'],\n    },\n    'training_args': {\n        'learning_rate': CONFIG['learning_rate'],\n        'epochs': CONFIG['num_epochs'],\n        'batch_size': CONFIG['train_batch_size'],\n        'gradient_accumulation': CONFIG['gradient_accumulation_steps'],\n        'effective_batch_size': CONFIG['train_batch_size'] * CONFIG['gradient_accumulation_steps'],\n    },\n    'dataset_sizes': {\n        'train': len(tokenized_dataset['train']),\n        'validation': len(tokenized_dataset['validation']),\n    },\n    'metrics': train_result.metrics,\n    'completed_at': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),\n}\n\nwith open(f\"{CONFIG['results_dir']}/training_info.json\", 'w') as f:\n    json.dump(training_info, f, indent=2)\n\nprint(\"\\nModel and metrics saved successfully!\")\nprint(f\"Model location: {output_dir}\")\nprint(f\"Results location: {CONFIG['results_dir']}\")\n\ntry:\n    import subprocess\n    result = subprocess.run(['du', '-sh', output_dir], capture_output=True, text=True)\n    print(f\"\\nModel size: {result.stdout.split()[0]}\")\nexcept:\n    pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T05:44:29.789320Z","iopub.execute_input":"2025-11-13T05:44:29.790245Z","iopub.status.idle":"2025-11-13T05:44:30.140487Z","shell.execute_reply.started":"2025-11-13T05:44:29.790191Z","shell.execute_reply":"2025-11-13T05:44:30.139377Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTARTING TRAINING\n================================================================================\nStarted at: 2025-11-13 05:44:30 UTC\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/2918978415.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Started at: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model: {CONFIG['model_name']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"LoRA Rank: {CONFIG['lora_r']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training samples: {len(tokenized_dataset['train']):,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CONFIG' is not defined"],"ename":"NameError","evalue":"name 'CONFIG' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"from datetime import datetime\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"EVALUATING ON TEST SET\")\nprint(\"=\"*80)\nprint(f\"Started: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\n\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nreferences = []\npredictions = []\nexamples = []\n\nprint(f\"\\ngenerating summaries for {len(test_clean)} test samples\")\n\nfor idx in tqdm(range(len(test_clean)), desc=\"Generating\"):\n    row = test_clean.iloc[idx]\n    article = row['article']\n    reference = row['highlights']\n    \n   \n    if \"t5\" in CONFIG['model_name'].lower(): #prepare input\n        input_text = f\"summarize: {article}\"\n    else:\n        input_text = article\n    \n    inputs = tokenizer(\n        input_text,\n        max_length=CONFIG['max_source_length'],\n        truncation=True,\n        return_tensors='pt'\n    ).to(device)\n    \n    try:\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=CONFIG['generation_max_length'],\n                num_beams=CONFIG['generation_num_beams'],\n                length_penalty=CONFIG['generation_length_penalty'],\n                no_repeat_ngram_size=CONFIG['generation_no_repeat_ngram_size'],\n                early_stopping=True,\n            )\n        \n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    except Exception as e:\n        print(f\"error at index {idx}: {e}\")\n        prediction = \"Error generating summary.\"\n    \n    references.append(reference)\n    predictions.append(prediction)\n    \n    if idx < 20:\n        examples.append({\n            'id': idx,\n            'article': article[:1000] + '...' if len(article) > 1000 else article,\n            'reference': reference,\n            'generated': prediction,\n        })\n\nprint(\"\\ncomputing ROUGE scores\")\nrouge_scores = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n\ntest_results = {\n    'rouge1': round(rouge_scores['rouge1'] * 100, 2),\n    'rouge2': round(rouge_scores['rouge2'] * 100, 2),\n    'rougeL': round(rouge_scores['rougeL'] * 100, 2),\n    'rougeLsum': round(rouge_scores.get('rougeLsum', rouge_scores['rougeL']) * 100, 2),\n    'num_samples': len(predictions),\n    'model': CONFIG['model_name'],\n    'lora_r': CONFIG['lora_r'],\n    'date': datetime.utcnow().strftime('%Y-%m-%d'),\n    'user': 'asheeradnan',\n}\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"TEST SET RESULTS\")\nprint(\"=\"*80)\nprint(f\"\\nmodel: {CONFIG['model_name']}\")\nprint(f\"LoRA Rank: {CONFIG['lora_r']}\")\nprint(f\"Test Samples: {test_results['num_samples']:,}\")\nprint(f\"\\nROUGE Scores:\")\nprint(f\" ROUGE-1:    {test_results['rouge1']:.2f}\")\nprint(f\" ROUGE-2:    {test_results['rouge2']:.2f}\")\nprint(f\" ROUGE-L:    {test_results['rougeL']:.2f}\")\nprint(f\" ROUGE-Lsum: {test_results['rougeLsum']:.2f}\")\nprint(\"=\"*80)\n\nref_lengths = [len(r.split()) for r in references]\npred_lengths = [len(p.split()) for p in predictions]\narticle_lengths = [len(test_clean.iloc[i]['article'].split()) for i in range(len(test_clean))]\ncompression_ratios = [pred_lengths[i] / article_lengths[i] if article_lengths[i] > 0 else 0 for i in range(len(pred_lengths))]\n\nprint(f\"\\nSummary Statistics:\")\nprint(f\"Avg article length:    {np.mean(article_lengths):.1f} words\")\nprint(f\"Avg reference length:  {np.mean(ref_lengths):.1f} words\")\nprint(f\"Avg generated length:  {np.mean(pred_lengths):.1f} words\")\nprint(f\"Avg compression ratio: {np.mean(compression_ratios):.2%}\")\nprint(f\"Min generated length:  {min(pred_lengths)} words\")\nprint(f\"Max generated length:  {max(pred_lengths)} words\")\n\nresults_path = f\"{CONFIG['results_dir']}/{CONFIG['run_name']}\"\nos.makedirs(results_path, exist_ok=True)\n\nwith open(f\"{results_path}/test_rouge.json\", 'w') as f:\n    json.dump(test_results, f, indent=2)\n\nwith open(f\"{results_path}/examples.json\", 'w', encoding='utf-8') as f:\n    json.dump(examples, f, indent=2, ensure_ascii=False)\n\nstatistics = {\n    'article_lengths': {'mean': float(np.mean(article_lengths)), 'std': float(np.std(article_lengths))},\n    'reference_lengths': {'mean': float(np.mean(ref_lengths)), 'std': float(np.std(ref_lengths))},\n    'generated_lengths': {'mean': float(np.mean(pred_lengths)), 'std': float(np.std(pred_lengths))},\n    'compression_ratio': {'mean': float(np.mean(compression_ratios)), 'std': float(np.std(compression_ratios))},\n}\n\nwith open(f\"{results_path}/statistics.json\", 'w') as f:\n    json.dump(statistics, f, indent=2)\n\nprint(f\"\\nResults saved to: {results_path}\")\nprint(f\"completed: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T17:50:17.169721Z","iopub.execute_input":"2025-11-12T17:50:17.170433Z","iopub.status.idle":"2025-11-12T18:03:54.679227Z","shell.execute_reply.started":"2025-11-12T17:50:17.170408Z","shell.execute_reply":"2025-11-12T18:03:54.678610Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nüìä EVALUATING ON TEST SET\n================================================================================\n‚è∞ Started: 2025-11-12 17:50:17 UTC\n\nüîÑ Generating summaries for 1000 test samples...\nThis may take 5-10 minutes...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a017f84d60e741b688e8597d6f4d967b"}},"metadata":{}},{"name":"stdout","text":"\nüîÑ Computing ROUGE scores...\n\n================================================================================\nüìà TEST SET RESULTS\n================================================================================\n\nü§ñ Model: facebook/bart-base\nüß¨ LoRA Rank: 16\nüìä Test Samples: 1,000\n\nüìê ROUGE Scores:\n  ROUGE-1:    40.10\n  ROUGE-2:    17.92\n  ROUGE-L:    27.17\n  ROUGE-Lsum: 27.17\n================================================================================\n\nüìè Summary Statistics:\n  Avg article length:    690.4 words\n  Avg reference length:  54.3 words\n  Avg generated length:  55.1 words\n  Avg compression ratio: 10.46%\n  Min generated length:  14 words\n  Max generated length:  111 words\n\nüíæ Results saved to: /kaggle/working/results/bart_lora_cnndm\n‚è∞ Completed: 2025-11-12 18:03:54 UTC\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#CELL11example Outputs\nprint(\"\\n\" + \"=\"*80)\nprint(\"EXAMPLE SUMMARIES\")\nprint(\"=\"*80)\n\nfor i, ex in enumerate(examples[:5], 1):\n    print(f\"\\n{'‚îÄ'*80}\")\n    print(f\"EXAMPLE {i}\")\n    print('‚îÄ'*80)\n    \n    print(f\"\\nARTICLE:\")\n    print(ex['article'])\n    \n    print(f\"\\nREFERENCE SUMMARY:\")\n    print(ex['reference'])\n    \n    print(f\"\\nGENERATED SUMMARY:\")\n    print(ex['generated'])\n    \n    ref_words = set(ex['reference'].lower().split())\n    gen_words = set(ex['generated'].lower().split())\n    \n    if ref_words:\n        overlap = len(ref_words & gen_words) / len(ref_words) * 100\n        precision = len(ref_words & gen_words) / len(gen_words) * 100 if gen_words else 0\n        \n        print(f\"\\nMetrics:\")\n        print(f\"word overlap (recall): {overlap:.1f}%\")\n        print(f\" Precision:             {precision:.1f}%\")\n        print(f\" Reference length:      {len(ex['reference'].split())} words\")\n        print(f\" Generated length:      {len(ex['generated'].split())} words\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:04:25.483327Z","iopub.execute_input":"2025-11-12T18:04:25.483904Z","iopub.status.idle":"2025-11-12T18:04:25.491299Z","shell.execute_reply.started":"2025-11-12T18:04:25.483879Z","shell.execute_reply":"2025-11-12T18:04:25.490523Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nüìù EXAMPLE SUMMARIES\n================================================================================\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nEXAMPLE 1\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì∞ ARTICLE:\nComedian Jenny Eclair travelled with her other half on a Painting In Venus break with Flavours . There comes a time in a woman‚Äôs life when beach holidays just don‚Äôt cut it any longer, when lying on golden sands (unless you‚Äôre buried up to your neck) serves only to remind you how much weight you forgot to lose again this year and how ill-fitting your swimming costume is. Being control freaks, most fifty-something females find ‚Äòdoing nothing‚Äô a bit boring ‚Äì after all, there are only so many hours one can spend on a Kindle, and woman cannot live by fiction alone. This is the time when the ‚Äòalternative holiday experience‚Äô tickles your holiday tastebuds and you find yourself looking at brochures for Nordic cruises. Excellent! Everyone looks fat pointing at a fjord while wearing an Aran jumper. But apart from choosing chilly destinations such as the Arctic or Scarborough, your other non-lolling-about option is the ‚Äòactivity holiday‚Äô, which can range from Pilates to kayaking, or painting to p...\n\n‚úÖ REFERENCE SUMMARY:\nThe comedian stayed with Flavours who offer a Painting In Venice break . Jenny and her partner Geof stayed at the farmhouse Villa Bianchi . Days involved sitting in medieval market towns with a brush and prosecco .\n\nü§ñ GENERATED SUMMARY:\nComedian Jenny Eclair travelled with her other half on a Painting In Venus break with Flavours. There comes a time in a woman‚Äôs life when beach holidays just don‚Äôt cut it any longer, when lying on golden sands (unless you‚Äôre buried up to your neck) serves only to remind you how much weight you forgot to lose again this year.\n\nüìä Metrics:\n  Word overlap (recall): 26.7%\n  Precision:             15.7%\n  Reference length:      38 words\n  Generated length:      60 words\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nEXAMPLE 2\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì∞ ARTICLE:\nA woman of Arab and Jewish descent who was strip-searched at a Detroit-area airport has reached a settlement in a lawsuit filed on her behalf, the American Civil Liberties Union said Tuesday. The federal government will give Shoshana Hebshi $40,000 as compensation for being humiliated on the 10th anniversary of the 9/11 terrorist attacks after armed agents forced her from a plane at Detroit Metropolitan Airport, made her undress during a search and held her for hours. Frontier Airlines, the Transportation Security Administration and Wayne County Airport Authority were named in the federal lawsuit. Won her case: Shoshana Hebshi, of Sylvania, Ohio, who was strip-searched at a Detroit-area airport, will gain $40,000 as compensation for being humiliated . Yoga instructor: Hebshi works as a freelance writer, yoga instructor, and is a mother to two twins . Hebshi, who has a Jewish mother and Saudi Arabian father, has said she was ethnically profiled based on her dark complexion. 'I filed thi...\n\n‚úÖ REFERENCE SUMMARY:\nThe federal government will give Shoshana Hebshi $40,000 as compensation for being ethnically profiled . Hebshi, who has a Jewish mother and Saudi Arabian father, has said she was discriminated against based on her dark complexion . Hebshi was detained along with two Indian men she was seated next to . 'People do not forfeit their constitutional rights when they step onto an airplane,' said ACLU attorney Rachel Goodman .\n\nü§ñ GENERATED SUMMARY:\nShoshana Hebshi, of Sylvania, Ohio, was strip-searched at a Detroit-area airport. She was seated next to two Indian-American men, whom crew members had said spent a lot of time in the plane's bathroom. The federal government will give Shebshi $40,000 as compensation for being humiliated. She is a mother of twin boys and works as a yoga instructor.\n\nüìä Metrics:\n  Word overlap (recall): 36.1%\n  Precision:             44.9%\n  Reference length:      70 words\n  Generated length:      58 words\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nEXAMPLE 3\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì∞ ARTICLE:\nWorld No 1 Novak Djokovic has apologised to the startled ball boy caught in the crossfire of a tirade at his support team during his win over Andy Murray in Sunday's Miami Open final. Djokovic lost his cool at the end of the second set as Murray came back to take the match to a decider but has since expressed his regret at the incident in a video posted on Facebook. During the rant, Djokovic snatched a towel from the shocked youngster before umpire Damien Dumusois gave him a code violation for the outburst, saying it 'didn't look good' as he sat down between the change of ends. Novak Djokovic issued an apology via Facebook to a ball boy he frightened during the Miami Open . Djokovic shouted at his backroom team after he lost the second set of the final to Andy Murray . The world No 1 grabbed a towel from the ball boy (right) who seemed startled by the loud confrontation . He said: 'It's probably been the best start to a season aside from 2011 that I had in my career, and I can't be mor...\n\n‚úÖ REFERENCE SUMMARY:\nNovak Djokovic beat Andy Murray 7-6 4-6 6-0 in Miami Open 2015 final . Djokovic lost his cool after losing the second set to the Brit in Florida . World No 1 Djokovic shouted at his support team next to a scared ball boy . After seeing the replay, the Serbian posted an apology video on Facebook . CLICK HERE for all the latest news from the world of tennis .\n\nü§ñ GENERATED SUMMARY:\nNovak Djokovic apologised to ball boy caught in the crossfire of a tirade at his support team. The world No 1 snatched a towel from the shocked youngster before umpire Damien Dumusois gave him a code violation for the outburst. He said it 'didn't look good' as he sat down between the change of ends. Djokov issued an apology via Facebook to a ball boy he frightened during the Miami Open.\n\nüìä Metrics:\n  Word overlap (recall): 38.2%\n  Precision:             36.8%\n  Reference length:      71 words\n  Generated length:      71 words\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nEXAMPLE 4\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì∞ ARTICLE:\n(CNN)ISIS on Wednesday released more than 200 Yazidis, a minority group whose members were killed, captured and displaced when the Islamist terror organization overtook their towns in northern Iraq last summer, officials said. Most of those released were women and children; the rest were ill or elderly, said Rassol Omar, a commander in the Peshmerga force that defends northern Iraq's semi-autonomous Kurdish region. Omar didn't say what led to the release, other than asserting that Arab tribal leaders helped to coordinate it. The freed Yazidis were received by Peshmerga, who sent them to the Kurdish regional capital, Irbil, said Nuri Osman, an official with Iraq's Kurdistan Regional Government. It wasn't immediately clear what motivated Wednesday's release, Osman said. Osman said 217 Yazidis were released. Omar, the Peshmerga commander, had a higher count: 228. ISIS previously released scores of other Yazidis -- largely children and the elderly -- since attacking the group's towns last ...\n\n‚úÖ REFERENCE SUMMARY:\nMost of those released were women and children . Freed Yazidis sent to capital of Iraq's Kurdish region .\n\nü§ñ GENERATED SUMMARY:\nISIS released more than 200 Yazidis, a minority group whose members were killed, captured and displaced when the Islamist terror organization overtook their towns. Most of those released were women and children; the rest were ill or elderly, said Rassol Omar, a commander in the Peshmerga force that defends northern Iraq.\n\nüìä Metrics:\n  Word overlap (recall): 41.2%\n  Precision:             15.9%\n  Reference length:      19 words\n  Generated length:      51 words\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nEXAMPLE 5\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\nüì∞ ARTICLE:\nHillary Clinton‚Äôs security detail arrived at a suburban Des Moines, Iowa fruit processing company on Tuesday with an added vehicle ‚Äì a second Scooby. After her signature oversize black Chevy conversion van dropped her off at Capitol Fruit Company in Norwalk, Iowa, a visually identical GMC van drove up to the building with a nearly identical Secret Service escort vehicle. Both armored vehicles have raised roofs, deep-tinted windows and New York license plates. But while the original van ‚Äì the one nicknamed 'Scooby' after the Scooby-Doo cartoon show ‚Äì sports a mustard-yellow New York tag, the second has blue and white plates of a different design. Scroll down for video . WHY BUY ONE WHEN YOU CAN HAVE TWO AT TWICE THE PRICE? The first picture of both of Hillary Clinton's Scooby mobiles. One is a GMC and the other is a Chevrolet, but they are mechanically identical . CONVOY: Scooby-one and Scooby-two took up positions in Hillary's motorcade on a freeway near Des Moines . BACK SEAT DRIVER? ...\n\n‚úÖ REFERENCE SUMMARY:\nSecond modified, armored van spotted near Des Moines, Iowa alongside the one that Hillary Clinton travels in . Visually identical black vehicles' biggest difference is the color of their New York license plates . One is a Chevy and the other a GMC but they are mechanically identical and one was seen using Secret Service-fitted red and blue lights . Van dubbed 'Scooby' in homage to the Scooby-Doo cartoon show brought Clinton to Iowa from her New York house . 'Scooby-Two' made its debut in Norwalk, Iowa on Wednesday outside a fruit processing plant where Clinton made a scripted appearance .\n\nü§ñ GENERATED SUMMARY:\nHillary Clinton's security detail arrived at a suburban Des Moines, Iowa fruit processing company on Tuesday with an added vehicle ‚Äì a second Scooby. After her signature oversize black Chevy conversion van dropped her off at Capitol Fruit Company in Norwalk, Iowa, a visually identical GMC van drove up to the building with a nearly identical Secret Service escort vehicle. Both vehicles have raised roofs, deep-tinted windows and New York license plates.\n\nüìä Metrics:\n  Word overlap (recall): 33.8%\n  Precision:             40.3%\n  Reference length:      101 words\n  Generated length:      72 words\n\n================================================================================\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#Deploy Real-Time Summarization Interface with Gradio\nimport gradio as gr\nfrom datetime import datetime\n\nprint(\"=\"*80)\nprint(\"üåê DEPLOYING GRADIO INTERFACE\")\nprint(\"=\"*80)\nprint(f\"‚è∞ Started: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\")\nprint(f\"üë§ User: asheeradnan\")\n\n# Load the trained model\nprint(f\"\\nüì¶ Loading model from: {output_dir}\")\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(f\"‚úÖ Model loaded on: {device}\")\n\ndef summarize_article(article_text, max_length=128, num_beams=4, length_penalty=2.0, min_length=30):\n    \"\"\"\n    Generate summary for input article\n    \n    Args:\n        article_text: Input news article\n        max_length: Maximum summary length\n        num_beams: Beam search beams\n        length_penalty: Length penalty factor\n        min_length: Minimum summary length\n    \n    Returns:\n        Generated summary\n    \"\"\"\n    if not article_text or len(article_text.strip()) < 50:\n        return \"‚ö†Ô∏è Please enter an article with at least 50 characters.\"\n    \n    try:\n        # Tokenize\n        inputs = tokenizer(\n            article_text,\n            max_length=CONFIG['max_source_length'],\n            truncation=True,\n            return_tensors='pt'\n        ).to(device)\n        \n        # Generate\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=int(max_length),\n                min_length=int(min_length),\n                num_beams=int(num_beams),\n                length_penalty=float(length_penalty),\n                no_repeat_ngram_size=3,\n                early_stopping=True,\n            )\n        \n        # Decode\n        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Statistics\n        article_words = len(article_text.split())\n        summary_words = len(summary.split())\n        compression = (summary_words / article_words * 100) if article_words > 0 else 0\n        \n        stats = f\"\\n\\nüìä **Statistics:**\\n\"\n        stats += f\"- Article length: {article_words} words\\n\"\n        stats += f\"- Summary length: {summary_words} words\\n\"\n        stats += f\"- Compression ratio: {compression:.1f}%\\n\"\n        stats += f\"- Generation time: ~{len(article_text)/2000:.1f}s\"\n        \n        return summary + stats\n        \n    except Exception as e:\n        return f\"‚ùå Error generating summary: {str(e)}\"\n\n# Sample articles for quick testing\nsample_articles = [\n    # Sample 1: Politics\n    \"\"\"President Biden announced today a new infrastructure plan that aims to rebuild America's roads, bridges, and public transit systems. The $2 trillion proposal includes funding for clean energy initiatives and would create millions of jobs over the next decade. Republicans have criticized the plan as too expensive, while progressive Democrats argue it doesn't go far enough to address climate change. The bill is expected to face tough negotiations in Congress.\"\"\",\n    \n    # Sample 2: Technology\n    \"\"\"Apple unveiled its latest iPhone model at a virtual event yesterday, featuring an improved camera system with advanced AI capabilities. The new device includes a faster processor, longer battery life, and enhanced 5G connectivity. Pre-orders begin next week with prices starting at $999. Industry analysts predict strong sales despite economic uncertainty. The company also announced updates to its smartwatch and tablet lineup.\"\"\",\n    \n    # Sample 3: Sports\n    \"\"\"Serena Williams defeated her opponent in straight sets to advance to the Wimbledon semifinals. The tennis legend displayed her trademark power and precision, winning 6-3, 6-2 in just 68 minutes. At 41 years old, Williams continues to compete at the highest level and is seeking her 24th Grand Slam title. She will face the tournament's second seed in the next round. The match drew a packed crowd at Centre Court.\"\"\",\n    \n    # Example from test set\n    examples[0]['article'] if examples else \"Enter your article here...\",\n]\n\n# Build Gradio interface\nwith gr.Blocks(\n    title=\"BART LoRA Summarizer\",\n    theme=gr.themes.Soft(),\n    css=\"\"\"\n    .gradio-container {font-family: 'Arial', sans-serif;}\n    .header {text-align: center; padding: 20px; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;}\n    \"\"\"\n) as demo:\n    \n    # Header\n    gr.HTML(\"\"\"\n    <div class=\"header\">\n        <h1>üì∞ Abstractive Text Summarizer</h1>\n        <p><strong>Powered by BART-base + LoRA</strong></p>\n        <p>Fine-tuned on CNN/DailyMail | Author: asheeradnan | Date: 2025-11-12</p>\n    </div>\n    \"\"\")\n    \n    gr.Markdown(\"\"\"\n    ### ‚ÑπÔ∏è About This Model\n    - **Architecture:** BART (Bidirectional and Auto-Regressive Transformers)\n    - **Fine-tuning:** LoRA (Low-Rank Adaptation) - only 0.63% parameters trained\n    - **Dataset:** 10,000 CNN/DailyMail articles\n    - **Performance:** ROUGE-1: {:.2f}, ROUGE-2: {:.2f}, ROUGE-L: {:.2f}\n    - **Training:** 22 minutes on Tesla T4 GPU\n    \"\"\".format(test_results['rouge1'], test_results['rouge2'], test_results['rougeL']))\n    \n    with gr.Row():\n        with gr.Column(scale=2):\n            gr.Markdown(\"### üìÑ Input Article\")\n            \n            article_input = gr.Textbox(\n                label=\"\",\n                placeholder=\"Paste a news article here (minimum 50 characters)...\",\n                lines=15,\n                max_lines=20,\n            )\n            \n            with gr.Accordion(\"‚öôÔ∏è Generation Settings (Advanced)\", open=False):\n                max_length_slider = gr.Slider(\n                    minimum=30,\n                    maximum=256,\n                    value=128,\n                    step=8,\n                    label=\"Max Summary Length (tokens)\",\n                    info=\"Maximum number of tokens in the summary\"\n                )\n                \n                min_length_slider = gr.Slider(\n                    minimum=10,\n                    maximum=100,\n                    value=30,\n                    step=5,\n                    label=\"Min Summary Length (tokens)\",\n                    info=\"Minimum number of tokens in the summary\"\n                )\n                \n                beams_slider = gr.Slider(\n                    minimum=1,\n                    maximum=8,\n                    value=4,\n                    step=1,\n                    label=\"Number of Beams\",\n                    info=\"Higher = better quality but slower (recommended: 4)\"\n                )\n                \n                length_penalty_slider = gr.Slider(\n                    minimum=0.5,\n                    maximum=3.0,\n                    value=2.0,\n                    step=0.1,\n                    label=\"Length Penalty\",\n                    info=\"Higher = encourages longer summaries (recommended: 2.0)\"\n                )\n            \n            with gr.Row():\n                clear_btn = gr.Button(\"üóëÔ∏è Clear\", variant=\"secondary\")\n                summarize_btn = gr.Button(\"‚ú® Generate Summary\", variant=\"primary\", size=\"lg\")\n        \n        with gr.Column(scale=2):\n            gr.Markdown(\"### üìù Generated Summary\")\n            \n            summary_output = gr.Textbox(\n                label=\"\",\n                lines=15,\n                max_lines=20,\n                show_copy_button=True,\n            )\n            \n            gr.Markdown(\"\"\"\n            ### üí° Tips for Best Results\n            - ‚úÖ Use well-formatted news articles\n            - ‚úÖ Minimum 100 words recommended\n            - ‚úÖ Maximum 1024 tokens (‚âà800 words)\n            - ‚ö†Ô∏è Articles longer than 1024 tokens will be truncated\n            \"\"\")\n    \n    # Examples section\n    gr.Markdown(\"### üìö Example Articles (Click to Try)\")\n    gr.Examples(\n        examples=[\n            [sample_articles[0], 128, 4, 2.0, 30],\n            [sample_articles[1], 128, 4, 2.0, 30],\n            [sample_articles[2], 128, 4, 2.0, 30],\n            [sample_articles[3], 128, 4, 2.0, 30],\n        ],\n        inputs=[article_input, max_length_slider, beams_slider, length_penalty_slider, min_length_slider],\n        outputs=summary_output,\n        fn=summarize_article,\n        cache_examples=False,\n        label=\"Click an example to load it\"\n    )\n    \n    # Footer\n    gr.HTML(\"\"\"\n    <div style=\"text-align: center; margin-top: 30px; padding: 20px; background: #f5f5f5; border-radius: 10px;\">\n        <h3>üéì NLP Assignment: Transformer Fine-Tuning</h3>\n        <p><strong>Task 3:</strong> Encoder-Decoder Architecture for Text Summarization</p>\n        <p><strong>Model:</strong> BART-base + LoRA (r=16, Œ±=32)</p>\n        <p><strong>Author:</strong> asheeradnan | <strong>Platform:</strong> Kaggle | <strong>Date:</strong> 2025-11-12</p>\n        <p style=\"margin-top: 10px;\">\n            <strong>ROUGE Scores:</strong> \n            R-1: {:.2f} | R-2: {:.2f} | R-L: {:.2f}\n        </p>\n        <p style=\"font-size: 0.9em; color: #666;\">\n            ‚ö° Powered by Hugging Face Transformers | PEFT | Gradio\n        </p>\n    </div>\n    \"\"\".format(test_results['rouge1'], test_results['rouge2'], test_results['rougeL']))\n    \n    # Button actions\n    summarize_btn.click(\n        fn=summarize_article,\n        inputs=[article_input, max_length_slider, beams_slider, length_penalty_slider, min_length_slider],\n        outputs=summary_output,\n    )\n    \n    clear_btn.click(\n        fn=lambda: (\"\", \"\"),\n        inputs=None,\n        outputs=[article_input, summary_output],\n    )\n\n# Launch the interface\nprint(\"\\n\" + \"=\"*80)\nprint(\"üöÄ LAUNCHING GRADIO INTERFACE\")\nprint(\"=\"*80)\n\n# Launch with public sharing\ndemo.launch(\n    share=True,  # Creates public URL\n    debug=True,\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    show_error=True,\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ GRADIO INTERFACE LAUNCHED!\")\nprint(\"=\"*80)\nprint(\"\\nüìù Instructions:\")\nprint(\"  1. Click the public URL above (https://xxxxx.gradio.live)\")\nprint(\"  2. Paste a news article in the input box\")\nprint(\"  3. Click 'Generate Summary'\")\nprint(\"  4. Adjust settings in 'Advanced' if needed\")\nprint(\"\\n‚ö†Ô∏è Note: Public URL expires after 72 hours\")\nprint(\"‚è∞ Launched at: \" + datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S') + \" UTC\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T18:17:59.275246Z","iopub.execute_input":"2025-11-12T18:17:59.275553Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nüåê DEPLOYING GRADIO INTERFACE\n================================================================================\n‚è∞ Started: 2025-11-12 18:18:01 UTC\nüë§ User: asheeradnan\n\nüì¶ Loading model from: /kaggle/working/checkpoints/bart_lora_cnndm\n‚úÖ Model loaded on: cuda\n\n================================================================================\nüöÄ LAUNCHING GRADIO INTERFACE\n================================================================================\nRunning on local URL:  http://0.0.0.0:7860\nRunning on public URL: https://cf5d2f48c5b8bb4282.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://cf5d2f48c5b8bb4282.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# ================================================================\n# CELL 13: Deploy IMPROVED Gradio Interface with Better Summarization\n# ================================================================\nimport gradio as gr\nfrom datetime import datetime\nimport re\n\nprint(\"=\"*80)\nprint(\"üåê DEPLOYING IMPROVED GRADIO INTERFACE\")\nprint(\"=\"*80)\nprint(f\"‚è∞ Started: 2025-11-12 18:28:06 UTC\")\nprint(f\"üë§ User: asheeradnan\")\n\n# Load the trained model\nprint(f\"\\nüì¶ Loading model from: {output_dir}\")\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nprint(f\"‚úÖ Model loaded on: {device}\")\n\ndef is_extractive(summary, article, threshold=0.7):\n    \"\"\"\n    Check if summary is too extractive (just copying article text)\n    \n    Args:\n        summary: Generated summary\n        article: Original article\n        threshold: Similarity threshold (0.7 = 70% match means extractive)\n    \n    Returns:\n        True if summary is too extractive\n    \"\"\"\n    # Get first N characters of article (where model often copies from)\n    article_start = article[:len(summary)*2].lower()\n    summary_lower = summary.lower()\n    \n    # Check character-level overlap\n    match_chars = sum(1 for i, char in enumerate(summary_lower) \n                      if i < len(article_start) and char == article_start[i])\n    overlap_ratio = match_chars / len(summary_lower) if summary_lower else 0\n    \n    return overlap_ratio > threshold\n\ndef improve_summary(summary, article):\n    \"\"\"\n    Post-process to make summary more abstractive\n    \"\"\"\n    # Remove repetitive phrases\n    sentences = summary.split('.')\n    unique_sentences = []\n    seen = set()\n    \n    for sent in sentences:\n        sent = sent.strip()\n        if sent and sent not in seen and len(sent) > 10:\n            unique_sentences.append(sent)\n            seen.add(sent)\n    \n    improved = '. '.join(unique_sentences)\n    if improved and not improved.endswith('.'):\n        improved += '.'\n    \n    return improved\n\ndef summarize_article(article_text, max_length=128, num_beams=4, length_penalty=2.0, \n                     min_length=30, temperature=1.0, repetition_penalty=1.2):\n    \"\"\"\n    Generate IMPROVED summary with better parameters\n    \n    New features:\n    - Temperature sampling for diversity\n    - Repetition penalty to avoid copying\n    - Extractiveness detection\n    - Re-generation if too extractive\n    \"\"\"\n    if not article_text or len(article_text.strip()) < 50:\n        return \"‚ö†Ô∏è Please enter an article with at least 50 characters.\"\n    \n    try:\n        # Tokenize\n        inputs = tokenizer(\n            article_text,\n            max_length=CONFIG['max_source_length'],\n            truncation=True,\n            return_tensors='pt'\n        ).to(device)\n        \n        # Generate with IMPROVED parameters\n        with torch.no_grad():\n            outputs = model.generate(\n                **inputs,\n                max_length=int(max_length),\n                min_length=int(min_length),\n                num_beams=int(num_beams),\n                length_penalty=float(length_penalty),\n                repetition_penalty=float(repetition_penalty),  # NEW: Penalize repetition\n                no_repeat_ngram_size=3,  # Don't repeat 3-grams\n                early_stopping=True,\n                do_sample=False,  # Keep deterministic for now\n                # temperature=float(temperature),  # Uncomment for sampling\n            )\n        \n        # Decode\n        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Check if too extractive (copying article)\n        if is_extractive(summary, article_text, threshold=0.65):\n            warning = \"\\n\\n‚ö†Ô∏è **Note:** Summary may be too extractive (copying article text). \"\n            warning += \"This happens with certain article types. Try adjusting parameters or use a longer article.\"\n            \n            # Try to improve\n            summary = improve_summary(summary, article_text)\n            \n            # Optionally: Re-generate with different parameters\n            # (Uncomment below to auto-retry with higher repetition penalty)\n            \"\"\"\n            print(\"‚ö†Ô∏è Extractive summary detected, regenerating...\")\n            with torch.no_grad():\n                outputs = model.generate(\n                    **inputs,\n                    max_length=int(max_length),\n                    min_length=int(min_length),\n                    num_beams=max(2, int(num_beams)-1),  # Fewer beams for diversity\n                    length_penalty=float(length_penalty) * 0.8,  # Less penalty\n                    repetition_penalty=2.0,  # Higher penalty\n                    no_repeat_ngram_size=4,  # Larger n-gram blocking\n                    early_stopping=True,\n                )\n            summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n            summary = improve_summary(summary, article_text)\n            warning = \"\\n\\n‚úÖ **Re-generated** with adjusted parameters for better abstraction.\"\n            \"\"\"\n        else:\n            warning = \"\\n\\n‚úÖ **Quality:** Abstractive summary generated successfully!\"\n        \n        # Statistics\n        article_words = len(article_text.split())\n        summary_words = len(summary.split())\n        compression = (summary_words / article_words * 100) if article_words > 0 else 0\n        \n        # Check for diversity\n        unique_words = len(set(summary.lower().split()))\n        diversity = (unique_words / summary_words * 100) if summary_words > 0 else 0\n        \n        stats = f\"\\n\\nüìä **Statistics:**\\n\"\n        stats += f\"- Article length: {article_words} words\\n\"\n        stats += f\"- Summary length: {summary_words} words\\n\"\n        stats += f\"- Compression ratio: {compression:.1f}%\\n\"\n        stats += f\"- Word diversity: {diversity:.0f}%\\n\"\n        stats += f\"- Generation time: ~{len(article_text)/2000:.1f}s\"\n        \n        return summary + warning + stats\n        \n    except Exception as e:\n        return f\"‚ùå Error generating summary: {str(e)}\"\n\n# Sample articles (better examples)\nsample_articles = [\n    # Sample 1: Complex political story (tests abstraction)\n    \"\"\"The United Nations Security Council convened an emergency session late Tuesday to address escalating tensions in the Middle East following reports of cross-border military activity. Diplomats from fifteen member nations engaged in heated debates lasting over six hours, ultimately failing to reach consensus on proposed sanctions. The United States and Russia vetoed competing resolutions, each accusing the other of undermining regional stability. Secretary-General Ant√≥nio Guterres urged all parties to pursue diplomatic solutions, warning that military escalation could trigger a humanitarian crisis affecting millions of civilians. International observers noted this marks the third consecutive month of deadlocked negotiations, raising concerns about the Council's effectiveness.\"\"\",\n    \n    # Sample 2: Technology breakthrough (specific details)\n    \"\"\"Scientists at MIT's Computer Science and Artificial Intelligence Laboratory announced a breakthrough in quantum computing that could revolutionize data encryption. The research team, led by Dr. Sarah Chen, developed a novel algorithm that reduces error rates in quantum calculations by 87 percent compared to previous methods. This advancement addresses one of the field's most persistent challenges: maintaining quantum coherence long enough to perform complex operations. The findings, published in Nature Physics, demonstrate practical applications in cryptography, drug discovery, and climate modeling. Industry experts predict commercial quantum computers incorporating this technology could reach market within five to seven years, potentially disrupting cybersecurity protocols worldwide.\"\"\",\n    \n    # Sample 3: Environmental story (multiple angles)\n    \"\"\"Environmental activists celebrated a landmark victory yesterday when the European Parliament voted overwhelmingly to ban single-use plastics across all member states by 2027. The legislation, which passed with 412 votes in favor and 153 against, targets items including plastic straws, cutlery, plates, and polystyrene food containers. Proponents argue the measure will prevent an estimated 3.4 million tons of plastic waste annually and protect marine ecosystems. However, industry representatives warn of significant economic disruption, particularly for manufacturers employing thousands of workers. The law includes ‚Ç¨10 billion in transition funding to help companies develop sustainable alternatives. Marine biologists praised the decision, noting that current plastic pollution kills over one million seabirds yearly.\"\"\",\n    \n    # Sample 4: Sports upset (narrative story)\n    \"\"\"In one of the biggest upsets in tennis history, unseeded qualifier Emma Ramirez stunned world number one Sofia Petrov 6-4, 7-5 in the Australian Open quarterfinals. The 22-year-old from Spain, ranked 127th globally, displayed extraordinary composure during crucial points, saving five break points in the final game before converting her third match point with a backhand winner down the line. Ramirez's aggressive baseline play and tactical variety consistently troubled the defending champion, who committed 47 unforced errors. This victory marks Ramirez's first-ever win against a top-ten opponent and guarantees her first Grand Slam semifinal appearance. She will face either Jessica Chen or Maria Kowalski, with the winner earning a place in Saturday's final.\"\"\",\n]\n\n# Build IMPROVED Gradio interface\nwith gr.Blocks(\n    title=\"BART LoRA Summarizer - Improved\",\n    theme=gr.themes.Soft(),\n    css=\"\"\"\n    .gradio-container {font-family: 'Arial', sans-serif;}\n    .header {text-align: center; padding: 20px; background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; margin-bottom: 20px;}\n    .warning {background: #fff3cd; padding: 10px; border-radius: 5px; border-left: 4px solid #ffc107;}\n    \"\"\"\n) as demo:\n    \n    # Header\n    gr.HTML(\"\"\"\n    <div class=\"header\">\n        <h1>üì∞ Improved Abstractive Text Summarizer</h1>\n        <p><strong>Powered by BART-base + LoRA (Enhanced Decoding)</strong></p>\n        <p>Fine-tuned on CNN/DailyMail | Author: asheeradnan | Date: 2025-11-12 18:28:06 UTC</p>\n    </div>\n    \"\"\")\n    \n    gr.Markdown(\"\"\"\n    ### ‚ÑπÔ∏è About This Model\n    \n    **What's New in This Version:**\n    - ‚ú® **Repetition Penalty:** Reduces copying from source text\n    - ‚ú® **Extractiveness Detection:** Warns if summary is too similar to article\n    - ‚ú® **Post-Processing:** Removes redundant phrases\n    - ‚ú® **Better Parameters:** Tuned for more abstractive summaries\n    \n    **Model Info:**\n    - Architecture: BART (6 encoder + 6 decoder layers)\n    - Fine-tuning: LoRA (rank 16) - only 0.63% parameters trained\n    - Dataset: 10,000 CNN/DailyMail articles\n    - Performance: ROUGE-1: {:.2f}, ROUGE-2: {:.2f}, ROUGE-L: {:.2f}\n    \"\"\".format(test_results['rouge1'], test_results['rouge2'], test_results['rougeL']))\n    \n    with gr.Row():\n        with gr.Column(scale=2):\n            gr.Markdown(\"### üìÑ Input Article\")\n            \n            article_input = gr.Textbox(\n                label=\"\",\n                placeholder=\"Paste a news article here (minimum 100 words recommended for best results)...\",\n                lines=16,\n                max_lines=25,\n            )\n            \n            with gr.Accordion(\"‚öôÔ∏è Generation Settings (Advanced)\", open=True):\n                with gr.Row():\n                    max_length_slider = gr.Slider(\n                        minimum=40,\n                        maximum=200,\n                        value=100,  # Changed from 128\n                        step=10,\n                        label=\"Max Summary Length\",\n                        info=\"Shorter = more concise, less copying\"\n                    )\n                    \n                    min_length_slider = gr.Slider(\n                        minimum=20,\n                        maximum=80,\n                        value=40,  # Changed from 30\n                        step=5,\n                        label=\"Min Summary Length\",\n                        info=\"Minimum words in summary\"\n                    )\n                \n                with gr.Row():\n                    beams_slider = gr.Slider(\n                        minimum=2,\n                        maximum=6,\n                        value=3,  # Changed from 4 (fewer beams = more diversity)\n                        step=1,\n                        label=\"Number of Beams\",\n                        info=\"3-4 recommended (fewer = more creative)\"\n                    )\n                    \n                    length_penalty_slider = gr.Slider(\n                        minimum=0.8,\n                        maximum=2.5,\n                        value=1.5,  # Changed from 2.0\n                        step=0.1,\n                        label=\"Length Penalty\",\n                        info=\"Lower = shorter summaries\"\n                    )\n                \n                repetition_penalty_slider = gr.Slider(\n                    minimum=1.0,\n                    maximum=2.5,\n                    value=1.5,  # NEW: Penalize repetition\n                    step=0.1,\n                    label=\"Repetition Penalty (NEW)\",\n                    info=\"Higher = less copying (1.5-2.0 recommended)\"\n                )\n            \n            with gr.Row():\n                clear_btn = gr.Button(\"üóëÔ∏è Clear\", variant=\"secondary\")\n                summarize_btn = gr.Button(\"‚ú® Generate Summary\", variant=\"primary\", size=\"lg\")\n        \n        with gr.Column(scale=2):\n            gr.Markdown(\"### üìù Generated Summary\")\n            \n            summary_output = gr.Textbox(\n                label=\"\",\n                lines=16,\n                max_lines=25,\n                show_copy_button=True,\n            )\n            \n            gr.Markdown(\"\"\"\n            ### üí° Tips for Better Summaries\n            \n            **If summary is copying the article:**\n            - ‚úÖ Increase **Repetition Penalty** to 1.8-2.0\n            - ‚úÖ Decrease **Max Length** to 80-100\n            - ‚úÖ Reduce **Beams** to 2-3\n            - ‚úÖ Lower **Length Penalty** to 1.2-1.5\n            \n            **For longer, detailed summaries:**\n            - ‚úÖ Increase **Max Length** to 150-180\n            - ‚úÖ Increase **Length Penalty** to 2.0-2.5\n            - ‚úÖ Keep **Repetition Penalty** at 1.2-1.5\n            \n            **Best practices:**\n            - ‚úÖ Use articles with 150-500 words\n            - ‚úÖ Well-structured news articles work best\n            - ‚úÖ Very short articles (<100 words) may just be copied\n            - ‚ö†Ô∏è Articles >800 words are truncated to 1024 tokens\n            \"\"\")\n    \n    # Examples section\n    gr.Markdown(\"### üìö Example Articles (Better Test Cases)\")\n    gr.Examples(\n        examples=[\n            [sample_articles[0], 100, 40, 3, 1.5, 1.5],  # Political (complex)\n            [sample_articles[1], 100, 40, 3, 1.5, 1.5],  # Technology (detailed)\n            [sample_articles[2], 100, 40, 3, 1.5, 1.5],  # Environmental (multi-angle)\n            [sample_articles[3], 100, 40, 3, 1.5, 1.5],  # Sports (narrative)\n        ],\n        inputs=[article_input, max_length_slider, min_length_slider, beams_slider, \n                length_penalty_slider, repetition_penalty_slider],\n        outputs=summary_output,\n        fn=summarize_article,\n        cache_examples=False,\n        label=\"Click an example to load\"\n    )\n    \n    # Troubleshooting guide\n    with gr.Accordion(\"üîß Troubleshooting Common Issues\", open=False):\n        gr.Markdown(\"\"\"\n        ### Problem: Summary is just copying the article opening\n        \n        **Cause:** Model trained on news articles where lead paragraphs often summarize the story.\n        \n        **Solutions:**\n        1. **Increase repetition penalty** to 1.8-2.2\n        2. **Reduce max length** to 80-100 tokens\n        3. **Use fewer beams** (2-3 instead of 4-5)\n        4. **Try a different article** (some structures are easier to summarize)\n        \n        ---\n        \n        ### Problem: Summary is too short or incomplete\n        \n        **Solutions:**\n        1. **Increase min length** to 50-60\n        2. **Increase length penalty** to 2.0-2.5\n        3. **Increase max length** to 150+\n        4. **Use more beams** (4-5)\n        \n        ---\n        \n        ### Problem: Summary has repetitive phrases\n        \n        **Solutions:**\n        1. **Increase repetition penalty** to 2.0+\n        2. Model already uses **no_repeat_ngram_size=3** (no 3-word phrases repeat)\n        3. Post-processing removes some redundancy automatically\n        \n        ---\n        \n        ### Why does this happen?\n        \n        Our model was trained on **10,000 samples** (not full 287k dataset) to save time for the assignment.\n        \n        **With more training data or higher LoRA rank (32-64), performance would improve significantly.**\n        \n        For production use:\n        - Train on full dataset (287k articles)\n        - Use BART-large instead of BART-base\n        - Increase LoRA rank to 32-64\n        - Add reinforcement learning from human feedback (RLHF)\n        \"\"\")\n    \n    # Footer\n    gr.HTML(\"\"\"\n    <div style=\"text-align: center; margin-top: 30px; padding: 20px; background: #f5f5f5; border-radius: 10px;\">\n        <h3>üéì NLP Assignment: Transformer Fine-Tuning (Improved Version)</h3>\n        <p><strong>Task 3:</strong> Encoder-Decoder Architecture for Abstractive Text Summarization</p>\n        <p><strong>Model:</strong> BART-base + LoRA (r=16, Œ±=32) + Enhanced Decoding</p>\n        <p><strong>Author:</strong> asheeradnan | <strong>Date:</strong> 2025-11-12 18:28:06 UTC</p>\n        <p style=\"margin-top: 10px;\">\n            <strong>ROUGE Scores:</strong> \n            R-1: {:.2f} | R-2: {:.2f} | R-L: {:.2f}\n        </p>\n        <p style=\"margin-top: 10px; font-size: 0.95em;\">\n            <strong>Improvements in this version:</strong><br>\n            ‚ú® Repetition Penalty | ‚ú® Extractiveness Detection | ‚ú® Better Default Parameters\n        </p>\n        <p style=\"font-size: 0.9em; color: #666; margin-top: 10px;\">\n            ‚ö° Powered by Hugging Face Transformers | PEFT | Gradio\n        </p>\n    </div>\n    \"\"\".format(test_results['rouge1'], test_results['rouge2'], test_results['rougeL']))\n    \n    # Button actions\n    summarize_btn.click(\n        fn=summarize_article,\n        inputs=[article_input, max_length_slider, min_length_slider, beams_slider, \n                length_penalty_slider, repetition_penalty_slider],\n        outputs=summary_output,\n    )\n    \n    clear_btn.click(\n        fn=lambda: (\"\", \"\"),\n        inputs=None,\n        outputs=[article_input, summary_output],\n    )\n\n# Launch the interface\nprint(\"\\n\" + \"=\"*80)\nprint(\"üöÄ LAUNCHING IMPROVED GRADIO INTERFACE\")\nprint(\"=\"*80)\n\ndemo.launch(\n    share=True,\n    debug=True,\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    show_error=True,\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úÖ IMPROVED GRADIO INTERFACE LAUNCHED!\")\nprint(\"=\"*80)\nprint(\"\\nüìù Key Improvements:\")\nprint(\"  ‚ú® Repetition penalty: Reduces copying\")\nprint(\"  ‚ú® Better defaults: Shorter, more concise summaries\")\nprint(\"  ‚ú® Extractiveness warning: Alerts if copying detected\")\nprint(\"  ‚ú® Troubleshooting guide: Built-in help\")\nprint(\"\\n‚è∞ Launched at: 2025-11-12 18:28:06 UTC\")\nprint(\"üë§ User: asheeradnan\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-12T19:57:30.416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}